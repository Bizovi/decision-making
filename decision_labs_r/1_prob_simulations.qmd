---
title: "Simplest generative models"
author: "Mihai Bizovi"
format: html
---

## Birthday paradox

Find a colleague near you, discuss for 3 minutes how many people you need in a room ($n$) so that the probability of any two people having a matching birthdays is close to 0.5. Or the other way around, given there are $n = 30$, what is the probability of a matching birthday? In what range is your answer $[0, 0.19), [0.20, 0.39), [0.4, 0.59), [0.6, 0.79), [0.8, 1]$?

> Tip: think of boundary conditions and how many possible pairs there are for a given $n$.

```{r load-packages}
#| warning: false

library(tidyverse)
library(viridisLite)
```


```{r analytical-solution}
#| fig-cap: "Analytical solution"

sim <- tibble(
    nr_people = 2:70,
    prob = sapply(nr_people, \(x) 1 - prod((366 - 1:x) / 365))
)

prob_half <- sim |> 
    mutate(diff = abs(0.5-prob)) |> 
    arrange(diff) |> first()

prob_half
```

Let's see how the analytical solution looks like. It takes a lot of effort to do a nice plot in base R, this is why we will mostly use `ggplot2` in this course.

```{r plotting}
#| code-fold: true

par(# mar = c(3, 3, 3, 3),  # Dist' from plot to side of page
    mgp = c(3, 1, 0),       # Dist' plot to label
    las = 1,                # Rotate y-axis text
    tck = -.01,             # Reduce tick length
    xaxs = "i", yaxs = "i"  # Remove plot padding
) 

plot(
    x = sim$nr_people, y = sim$prob, type = "l", 
    ylab = "Prob. of match", xlab = "nr. people", lwd=3,
    main = paste0(
        "Only ", prob_half$nr_people, " people for a ", 
        round(prob_half$prob * 100, 1), "% chance of matching bday"
    ),
    axes = FALSE, # Don't plot the axes
	frame.plot = FALSE, # Remove the frame
	xlim = c(0, 70), ylim = c(0, 1), # Limits
	panel.first = abline(h = seq(0, 1, 0.25), col = "grey80")
)
segments(
    x0 = prob_half$nr_people, y0 = 0, 
    x1 = prob_half$nr_people, y1 = prob_half$prob,
    lty="dashed"
)
segments(
    x0 = 0, y0 = prob_half$prob, 
    x1 = prob_half$nr_people, y1 = prob_half$prob, 
    lty="dashed"
)
at <- pretty(sim$nr_people)
axis(side = 1, at = at, col = "grey40", line = 1, cex = 0.7)
at <- seq(0, 1, 0.25)
mtext(side = 2, text = at, at = at, col = "grey40", line = 1, cex = 0.9)
```

In realistic problems that we'll encounter in practice and the rest of the course, the math could be too difficult for us to derive an analytic solution. Other times, we don't even know where to start. This is where simulating the generating process is an essential skill. There are two workhorses we will leverage a lot in this course: `replicate` and `tidyr::crossing`.

```{r sim-base-r}
nr_people <- 30

simulate_birthdays <- function(nr_people, nr_sim = 10000) {
	birthday_events <- replicate(n = nr_sim, {
		birthdays <- sample(x = 1:365, size = nr_people, replace = TRUE)
		anyDuplicated(birthdays) > 0
	})
	mean(birthday_events)  # this returns implicitly!
}

pr_same_bday <- simulate_birthdays(nr_people)
bday_match_size <- sapply(2:90, simulate_birthdays, nr_sim = 10000)
```

A quick check of the results, show that probability of n = `r nr_people` people having a matching birthday is `r round(pr_same_bday, 2)`. Let's see now a totally different way of doing it with same results (the tidy way).

```{r sim-tidy}
summarised <- tidyr::crossing(
        people = seq(2, 60, 2), 
        trial  = 1:10000,
    ) |>
    dplyr::mutate(
        birthday = purrr::map(people, \(x) sample(365, x, replace = TRUE)), 
        multiple = purrr::map_lgl(birthday, \(x) any(duplicated(x)))
    ) |>
    dplyr::group_by(people) |>
    dplyr::summarise(chance = mean(multiple)) |>
    dplyr::mutate(
        # sapply would work too here
        analytical_solution = purrr::map_dbl(people, \(x) 1 - prod((366 - 1:x) / 365))
    )

# Visualizing the probability
ggplot(summarised) +
    geom_line(aes(people, chance)) +
    geom_line(aes(people, analytical_solution), lty="dashed", color = "darkred") + 
    scale_y_continuous(labels = scales::percent_format()) +
    labs(y = "Prob. matching birthday", x = "nr. people") + 
    theme_minimal()
```

Some possible applications:

- Hash collision, quick and dirty approximation for satellite collision
- Related problem -- partition problem (weights on 2 scales), balance them: e.g. Dota / MMR


## Showing up to a safari trip

```{r}
set.seed(13131)

prevalence_couples <- 0.6
prob_couple <- 0.6 + 0.4 * 0.6  # (1 - (1 - 0.6)**2)
prob_showup <- 0.85

# validate final proportion of couples and individuals
replicate(n = 10000, {
    first <- ifelse(rbinom(1, 1, prevalence_couples) == 1, "CC", "I")
    second <- ifelse(first == "CC", "", 
        ifelse(rbinom(1, 1, prevalence_couples) == 1, "CC", "I"))
    third <- ifelse(second == "I", "I", "")
    paste0(first, second, third)
}) |> grepl(pattern = "C") |> table() / 10000
```

```{r}
simulate_customers <- function(
    prevalence_couples = 0.6,
    prob_showup = 0.85,
    nr_sim = 10000
) {
    prob_couple <- prevalence_couples + 
        (1 - prevalence_couples) * prevalence_couples

    replicate(n = nr_sim, {
        has_couple <- rbinom(1, 1, prob_couple)
        y_ind <- rbinom(1, 3 - 2*has_couple, prob_showup)
        y_mix <- has_couple * 2 * rbinom(1, 1, prob_showup^2)
        y_ind + y_mix
    }) |> table() / nr_sim
}

simulate_customers()
```

```{r}
tibble(
    prevalence_couples = seq(0, 1, 0.01),
    prob_couple = prevalence_couples + (1 - prevalence_couples) * prevalence_couples
) |> 
    ggplot(aes(x = prevalence_couples, y = prob_couple)) + 
    geom_line() + 
    labs(x = "Prevalence of couples", y = "Probability couple makes reservation") + 
    theme_minimal()
```


```{r}
nr_sim <- 10000
tibble(
    has_couple = rbinom(nr_sim, 1, prob_couple),
    nr_individ = 3 - 2*has_couple,
    y_ind = purrr::map_int(nr_individ, \(x) rbinom(1, x, prob_showup)),
    y = y_ind + has_couple * 2 * purrr::map_int(has_couple, \(x) rbinom(1, 1, prob_showup^2)),
    model = "mixed"
) |> 
    select(y, model) |>
    rbind(tibble(
        y = rbinom(nr_sim, 3, prob_showup),
        model = "binom"
    )) |>
    group_by(model) |>
    count(y) |>
    mutate(prob = n / sum(n)) |>
    ggplot(aes(x = y, y = prob, fill = model)) + 
    geom_col(position = "dodge") + 
    labs(x = "Number of people showing up", y = "Proportion") +
    scale_fill_viridis_d(option = "E") + 
    scale_y_continuous(labels = scales::percent_format()) + 
    theme_minimal()
```

```{r}
set.seed(11131)

prob_grid <- seq(0, 1, 0.02)
sapply(
    prob_grid, 
    FUN = \(x) simulate_customers(prevalence_couples = x, prob_showup = 0.85, nr_sim = nr_sim)
) |> t() |> data.frame() |> tibble() |>
    mutate(
        prevalence = prob_grid,
        expect = 0 * X0 + 1 * X1 + 2 * X2 + 3 * X3,
        variance = (0^2*X0 + 1^2*X1 + 2^2*X2 + 3^2*X3) - expect ^2,
        loss_due_couples = expect - max(expect),
        loss_upper = loss_due_couples + 2 * sqrt(variance / nr_sim),
        loss_lower = loss_due_couples - 2 * sqrt(variance / nr_sim)
    ) |>
    ggplot(aes(x = prevalence, y = loss_due_couples)) + 
    geom_point(color = "darkred") +
    geom_segment(aes(
        y = loss_lower, yend = loss_upper, 
        x = prevalence, xend = prevalence
    )) +
    labs(x = "Prevalence of couples", y = "Expected loss w.r.t. independece") + 
    theme_minimal()
```


## Law of large numbers

```{r}
set.seed(137) # careful when setting seed to even number
nr_sim_pois <- 100000
lln_pois <- replicate(n = 3, {
    pois_sim <- rpois(nr_sim_pois, 4.5)
    seq(10, nr_sim_pois, 30) |> 
    sapply(\(x) pois_sim[1:x] |> mean())
}) |> data.frame() |> tibble()

lln_pois |>
    mutate(nr_samples = 10 + row_number() * 30) |> 
    pivot_longer(cols = c("X1", "X2", "X3")) |> 
    mutate(name = case_when(
        name == "X1" ~ "sim. 1",
        name == "X2" ~ "sim. 2",
        name == "X3" ~ "sim. 3"
    )) |>
    filter(nr_samples > 60 & nr_samples < 20000) |>
    ggplot(aes(x = nr_samples, y = value, col = name)) + 
    geom_line() + 
    geom_hline(yintercept = 4.5, lty = "dashed") + 
    scale_color_viridis_d() +
    theme_minimal()
```

```{r}
lln_pois |>
    mutate(nr_samples = 10 + (row_number() - 1) * 30) |> 
    filter(nr_samples >= 10 & nr_samples < 10000) |>
    mutate(theoretical = sqrt(4.5) / sqrt(nr_samples)) |>
    pivot_longer(cols = c("X1", "X2", "X3")) |> 
    mutate(name = case_when(
        name == "X1" ~ "sim. 1",
        name == "X2" ~ "sim. 2",
        name == "X3" ~ "sim. 3",
    )) |>
    mutate(sq_err = (value - 4.55)^2) |>
    group_by(nr_samples) |> summarise(sq_err = mean(sq_err), theoretical = mean(theoretical)) |>
    ggplot(aes(x = nr_samples, y = sq_err)) + 
    geom_line() + 
    geom_line(aes(x = nr_samples, y = theoretical), lty="dashed", col="darkred") +
    scale_color_viridis_d() +
    labs(x = "Sample size", y = "Squared error") +
    theme_minimal()
```




