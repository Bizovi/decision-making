---
title: "Birthday Paradox"
format: html
---

## Birthday paradox

Find your colleagues near you, discuss for 3 minutes. 
Give your best guess for a range of n (+- 10%) for which the chance would be 50%.

If you know the pigeonhole principle and a math trick, you could derive it analytically. 
Then, get a sense of the curve with a quick plot.

```{r load-packages}
library(tidyverse)
library(viridisLite)
```


```{r analytical-solution}
#| fig-cap: "Analytical solution"

sim <- tibble(
    nr_people = 2:70,
    prob = sapply(2:70, \(x) 1 - prod((366 - 1:x) / 365))
)

prob_half <- sim |> 
    mutate(diff = abs(0.5-prob)) |> 
    arrange(diff) |> first()

prob_half
```

It takes a lot of effort to do a nice plot in base R. 
On the bright side, you have no dependencies.

```{r plotting}
par(# mar = c(3, 3, 3, 3),  # Dist' from plot to side of page
    mgp = c(3, 1, 0),       # Dist' plot to label
    las = 1,                # Rotate y-axis text
    tck = -.01,             # Reduce tick length
    xaxs = "i", yaxs = "i"  # Remove plot padding
) 

plot(
    x = sim$nr_people, y = sim$prob, type = "l", 
    ylab = "Prob. of match", xlab = "nr. people", lwd=3,
    main = paste0(
        "Only ", prob_half$nr_people, " people for a ", 
        round(prob_half$prob * 100, 1), "% chance of matching bday"
    ),
    axes = FALSE, # Don't plot the axes
	frame.plot = FALSE, # Remove the frame
	xlim = c(0, 70), ylim = c(0, 1), # Limits
	panel.first = abline(h = seq(0, 1, 0.25), col = "grey80")
)
segments(
    x0 = prob_half$nr_people, y0 = 0, 
    x1 = prob_half$nr_people, y1 = prob_half$prob,
    lty="dashed"
)
segments(
    x0 = 0, y0 = prob_half$prob, 
    x1 = prob_half$nr_people, y1 = prob_half$prob, 
    lty="dashed"
)
at <- pretty(sim$nr_people)
axis(side = 1, at = at, col = "grey40", line = 1, cex = 0.7)
at <- seq(0, 1, 0.25)
mtext(side = 2, text = at, at = at, col = "grey40", line = 1, cex = 0.9)
```

In reality, the math could be too complex or we don't even know where to start.
Let's try it with base R

```{r sim-base-r}
nr_people <- 25 

simulate_birthdays <- function(nr_people, nr_sim = 10000) {
	birthday_events <- replicate(n = nr_sim, {
		birthdays <- sample(x = 1:365, size = nr_people, replace = TRUE)
		anyDuplicated(birthdays) > 0
	})
	mean(birthday_events)  # this returns implicitly!
}

pr_same_bday <- simulate_birthdays(nr_people)
bday_match_size <- sapply(2:90, simulate_birthdays, nr_sim = 10000)
```


Then a totally different way of doing it with same results: tidyverse.

```{r sim-tidy}
summarised <- tidyr::crossing(
        people = seq(2, 60, 2), 
        trial  = 1:10000,
    ) |>
    dplyr::mutate(
        birthday = purrr::map(people, \(x) sample(365, x, replace = TRUE)), 
        multiple = purrr::map_lgl(birthday, \(x) any(duplicated(x)))
    ) |>
    dplyr::group_by(people) |>
    dplyr::summarise(chance = mean(multiple)) |>
    dplyr::mutate(
        # sapply would work too here
        analytical_solution = purrr::map_dbl(people, \(x) 1 - prod((366 - 1:x) / 365))
    )

# Visualizing the probability
ggplot(summarised) +
    geom_line(aes(people, chance)) +
    geom_line(aes(people, analytical_solution), lty="dashed", color = "darkred") + 
    scale_y_continuous(labels = scales::percent_format()) +
    labs(y = "Prob. matching birthday", x = "nr. people") + 
    theme_minimal()
```

Some possible applications:

- Hash collision, quick and dirty approximation for satellite collision
- Related problem -- partition problem (weights on 2 scales), balance them: e.g. Dota / MMR


## Airplane Example

```{r}
set.seed(13131)

prevalence_couples <- 0.6
prob_couple <- 0.6 + 0.4 * 0.6  # (1 - (1 - 0.6)**2)
prob_showup <- 0.85

# validate final proportion of couples and individuals
replicate(n = 10000, {
    first <- ifelse(rbinom(1, 1, prevalence_couples) == 1, "CC", "I")
    second <- ifelse(first == "CC", "", ifelse(rbinom(1, 1, prevalence_couples) == 1, "CC", "I"))
    third <- ifelse(second == "I", "I", "")
    paste0(first, second, third)
}) |> grepl(pattern = "C") |> table() / 10000
```

```{r}
simulate_customers <- function(
    prevalence_couples = 0.6,
    prob_showup = 0.85,
    nr_sim = 10000
) {
    prob_couple <- prevalence_couples + (1 - prevalence_couples) * prevalence_couples  # (1 - (1 - 0.6)**2)

    replicate(n = 10000, {
        has_couple <- rbinom(1, 1, prob_couple)
        y_ind <- rbinom(1, 3 - 2*has_couple, prob_showup)
        y_mix <- has_couple * 2 * rbinom(1, 1, prob_showup^2)
        y_ind + y_mix
    }) |> table() / 10000
}

simulate_customers()
```

```{r}
tibble(
    prevalence_couples = seq(0, 1, 0.01),
    prob_couple = prevalence_couples + (1 - prevalence_couples) * prevalence_couples
) |> 
    ggplot(aes(x = prevalence_couples, y = prob_couple)) + 
    geom_line() + 
    labs(x = "Prevalence of couples", y = "Probability couple makes reservation") + 
    theme_minimal()
```


```{r}
tibble(
    has_couple = rbinom(10000, 1, prob_couple),
    nr_individ = 3 - 2*has_couple,
    y_ind = purrr::map_int(nr_individ, \(x) rbinom(1, x, prob_showup)),
    y = y_ind + has_couple * 2 * purrr::map_int(has_couple, \(x) rbinom(1, 1, prob_showup^2)),
    model = "mixed"
) |> 
    select(y, model) |>
    rbind(tibble(
        y = rbinom(10000, 3, prob_showup),
        model = "binom"
    )) |>
    group_by(model) |>
    count(y) |>
    mutate(prob = n / sum(n)) |>
    ggplot(aes(x = y, y = prob, fill = model)) + 
    geom_col(position = "dodge") + 
    labs(x = "Number of people showing up", y = "Proportion") +
    scale_fill_viridis_d(option = "E") + 
    scale_y_continuous(labels = scales::percent_format()) + 
    theme_minimal()
```
```{r}
set.seed(11131)
prob_grid <- seq(0, 1, 0.02)
sapply(
    prob_grid, 
    FUN = \(x) simulate_customers(prevalence_couples = x, prob_showup = 0.85, nr_sim = 10000)
) |> t() |> data.frame() |> tibble() |>
    mutate(
        prevalence = prob_grid,
        expect = 0 * X0 + 1 * X1 + 2 * X2 + 3 * X3,
        variance = (0^2*X0 + 1^2*X1 + 2^2*X2 + 3^2*X3) - expect ^2,
        loss_due_couples = expect - max(expect),
        loss_upper = loss_due_couples + 2 * sqrt(variance / 10000),
        loss_lower = loss_due_couples - 2 * sqrt(variance / 10000)
    ) |>
    ggplot(aes(x = prevalence, y = loss_due_couples)) + 
    geom_point(color = "darkred") +
    geom_segment(aes(
        y = loss_lower, yend = loss_upper, 
        x = prevalence, xend = prevalence
    )) +
    labs(x = "Prevalence of couples", y = "Expected loss w.r.t. independece") + 
    theme_minimal()
```


## Law of large numbers

```{r}
set.seed(137) # careful when setting seed to even number
nr_sim_pois <- 100000
lln_pois <- replicate(n = 3, {
    pois_sim <- rpois(nr_sim_pois, 4.5)
    seq(10, nr_sim_pois, 30) |> 
    sapply(\(x) pois_sim[1:x] |> mean())
}) |> data.frame() |> tibble()

lln_pois |>
    mutate(nr_samples = 10 + row_number() * 30) |> 
    pivot_longer(cols = c("X1", "X2", "X3")) |> 
    mutate(name = case_when(
        name == "X1" ~ "sim. 1",
        name == "X2" ~ "sim. 2",
        name == "X3" ~ "sim. 3"
    )) |>
    filter(nr_samples > 60 & nr_samples < 20000) |>
    ggplot(aes(x = nr_samples, y = value, col = name)) + 
    geom_line() + 
    geom_hline(yintercept = 4.5, lty = "dashed") + 
    scale_color_viridis_d() +
    theme_minimal()
```

```{r}
lln_pois |>
    mutate(nr_samples = 10 + (row_number() - 1) * 30) |> 
    filter(nr_samples >= 10 & nr_samples < 10000) |>
    mutate(theoretical = sqrt(4.5) / sqrt(nr_samples)) |>
    pivot_longer(cols = c("X1", "X2", "X3")) |> 
    mutate(name = case_when(
        name == "X1" ~ "sim. 1",
        name == "X2" ~ "sim. 2",
        name == "X3" ~ "sim. 3",
    )) |>
    mutate(sq_err = (value - 4.55)^2) |>
    group_by(nr_samples) |> summarise(sq_err = mean(sq_err), theoretical = mean(theoretical)) |>
    ggplot(aes(x = nr_samples, y = sq_err)) + 
    geom_line(se=FALSE) + 
    geom_line(aes(x = nr_samples, y = theoretical), lty="dashed", col="darkred") +
    scale_color_viridis_d() +
    labs(x = "Sample size", y = "Squared error") +
    theme_minimal()
```




